{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML \n",
    "# from IPython.core.debugger import Tracer\n",
    "from lxml import html\n",
    "import tensorflow as tf, sys\n",
    "import shutil\n",
    "import requests\n",
    "import subprocess\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from image_labeler import ImageLabeler\n",
    "\n",
    "labeler = ImageLabeler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classify a single image given the URL.\n",
    "def classify_images(image_urls, concurrent=False):    \n",
    "    # Downloads image locally\n",
    "    # Runs through the pre-trained classifier. See image_labeler.py for more info.\n",
    "    return labeler.get_tags(image_urls, concurrent)\n",
    "\n",
    "def confidence_levels(image):\n",
    "    print(\"High Quality Confidence: {}\".format(image['high_quality']))\n",
    "    print(\"Low Quality Confidence: {}\".format(image['low_quality']))\n",
    "\n",
    "def format_link(link):\n",
    "    return \"https:{}\".format(link)\n",
    "\n",
    "# If you want to get all the classification results for a listing's image.\n",
    "def classify_listing_images(listing_id, concurrent = False):\n",
    "    start_time = time.clock()\n",
    "    # Get the details URL for a given listing.\n",
    "    detail_url = 'https://www.tripping.com/details/test/1/1/{}'.format(listing_id)\n",
    "    # Parse the html tree and grab all the image links\n",
    "    html_tree = html.fromstring(requests.get(detail_url).content)\n",
    "    link_results = html_tree.xpath('.//img/@src')\n",
    "    links = [link_result for link_result in link_results if 'trippng' in link_result]\n",
    "    \n",
    "    image_urls = [format_link(link) for link in links]\n",
    "\n",
    "    scores = classify_images(image_urls, concurrent)    \n",
    "    default_image = scores[0]\n",
    "    \n",
    "    highest_quality = max(scores, key=lambda score:score['high_quality'])\n",
    "    lowest_quality = max(scores, key=lambda score:score['low_quality'])\n",
    "    \n",
    "    end_time = time.clock()\n",
    "    \n",
    "    print(\"Download & Classification for {} images took {}s\".format(len(image_urls), end_time - start_time))\n",
    "    \n",
    "    print(\"Current Image\")\n",
    "    confidence_levels(default_image)\n",
    "    display(Image(url=default_image['image_url']), width=50, height=50)\n",
    "    \n",
    "    print(\"'Best' Image by Score\")\n",
    "    confidence_levels(highest_quality)\n",
    "    display(Image(url=highest_quality['image_url']), width=50, height=50)\n",
    "\n",
    "    print(\"'Worst' Image by Score\")\n",
    "    confidence_levels(lowest_quality)\n",
    "    display(Image(url=lowest_quality['image_url']), width=50, height=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 23 images\n",
      "Download & Classification for 23 images took 39.39651699999999s\n",
      "Current Image\n",
      "High Quality Confidence: 0.994828999042511\n",
      "Low Quality Confidence: 0.005171039141714573\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s0.trippng.com/attachments/22a4ff1e7224061f7fdddcf86626ff82ff684291/store/0b5b6b5b72e99fa165da6e35a4d53f230a16bac4912c3b4480ad596e923f/media.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Best' Image by Score\n",
      "High Quality Confidence: 0.9972718358039856\n",
      "Low Quality Confidence: 0.0027282047085464\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s0.trippng.com/attachments/9521da00da726b33614689e84d9bd4aa36525d65/store/58b41492f150c90f9a48aa3680bcafeb69ed177b58675fc62f496d4f563f/media.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Worst' Image by Score\n",
      "High Quality Confidence: 2.1542515241890214e-05\n",
      "Low Quality Confidence: 0.9999784231185913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s0.trippng.com/attachments/b62fb571c2373a290eeeabe613df4c48b328c004/store/2e9a9316f0a1000dbbec0599b8ab8700187bb71b9811f57d59ce899b972d/media.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Given a listing ID, downloads the images and classifies (high or low quality) based on an existing model.\n",
    "classify_listing_images(18334505, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8 images\n",
      "Download & Classification for 8 images took 17.634882000000005s\n",
      "Current Image\n",
      "High Quality Confidence: 0.04572141170501709\n",
      "Low Quality Confidence: 0.9542785882949829\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s0.trippng.com/attachments/dbd1b521d439596615c556b3a72deef6b3f26565/store/69f1c6ec0f0714b3df158397ac00782af4165af83890b77a19f17ce1924e/media.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Best' Image by Score\n",
      "High Quality Confidence: 0.7176093459129333\n",
      "Low Quality Confidence: 0.28239068388938904\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s0.trippng.com/attachments/ee3d85f252c2d21751e6c3386a6c0c1156eab34f/store/359ddb4e20cd9d393c9ef50edfd5e1535abece4be25ef4c3fe269cd54d10/media.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Worst' Image by Score\n",
      "High Quality Confidence: 0.01832277700304985\n",
      "Low Quality Confidence: 0.9816772937774658\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s0.trippng.com/attachments/36e98c925927d99be8c7a2eed57e8dcfc2811636/store/9a4a7d2e45455d03e7599fa4c4ff2a92001edafcc0b2143889a0c14b0cba/media.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classify_listing_images(23221235, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 24 images\n",
      "Download & Classification for 24 images took 38.747987999999964s\n",
      "Current Image\n",
      "High Quality Confidence: 0.005216078832745552\n",
      "Low Quality Confidence: 0.9947839379310608\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s0.trippng.com/attachments/b87d4bf59820b5258bffbdfe90c95b9ca96d3f56/store/ef34fe6ab5fc3c99fe719b5e37cf43e695b0d11073d120577e0414508b53/media.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Best' Image by Score\n",
      "High Quality Confidence: 0.9997089505195618\n",
      "Low Quality Confidence: 0.0002910685434471816\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s0.trippng.com/attachments/e3c306433c2987697423b42f218f54a8865fdcf9/store/511124acd439264b979fdf5746688cb70d4d7f2371a2d4dc53282b58a81f/media.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Worst' Image by Score\n",
      "High Quality Confidence: 0.005216078832745552\n",
      "Low Quality Confidence: 0.9947839379310608\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s0.trippng.com/attachments/b87d4bf59820b5258bffbdfe90c95b9ca96d3f56/store/ef34fe6ab5fc3c99fe719b5e37cf43e695b0d11073d120577e0414508b53/media.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classify_listing_images(24177163, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 12 images\n",
      "Download & Classification for 12 images took 23.172560999999973s\n",
      "Current Image\n",
      "High Quality Confidence: 0.9866945743560791\n",
      "Low Quality Confidence: 0.01330543216317892\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s0.trippng.com/attachments/c724ac810f78f828340cacf24e03e4332f613544/store/5221eb6474a0620594394c3f52d3fa280ace17b647e13c225e0aab43b68c/media.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Best' Image by Score\n",
      "High Quality Confidence: 0.9961339235305786\n",
      "Low Quality Confidence: 0.003866139566525817\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s0.trippng.com/attachments/e9730dd005ba1810c408f65b8b8f9c02b7c205be/store/75dafbed5203b940ad0600648f5a66b2b2c4a86950ad552897ce9b862af2/media.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Worst' Image by Score\n",
      "High Quality Confidence: 0.48896324634552\n",
      "Low Quality Confidence: 0.51103675365448\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://s0.trippng.com/attachments/21829f8ef3a9609c0b3e0ca9ecc3fb76ffd2c75a/store/121f2efa943d6b40cc3e1c91b409d2205223c32c59cda2a5486d81c8fbf1/media.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classify_listing_images(28010749, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
